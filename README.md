# HRDerain

> Existing image deraining methods primarily focus on low-resolution images and exhibit inherent limitations when applied to high-resolution images. First, performing feature extraction directly on high-resolution
images leads to a signi cant increase in computational cost and memory consumption. Second, the inherent complexity of high-resolution rainy images, where rain streaks often intermingle with or severely obscure the background, imposes substantial demands on modelsâ€™ capacity to capture both local features and global contextual dependencies. Consequently, many existing models tend to over-smooth high-frequency details during rain removal, resulting in image blurring and the loss of critical structural information.To address these challenges, we propose an e cient Dual-branch Deraining Network (DDNet), which integrates frequency-domain feature interaction and dynamic feature fusion to enhance the representations capacity of its CNN and Transformer branches. Speci cally, we propose an Adaptive Frequency Reciprocal Module (AFRM) that adaptively generates frequency spectral lters to enable mutual reinforcement and interaction between the two branches. We further propose a Discrete Cosine Transform (DCT) based Multi Spectral Fusion Module (MSFM) to dynamically fuse the decoded features from both branches, thereby promoting e ective aggregation of multi-spectral information. Moreover, to address the potential feature disparities and uncertain knowledge gaps between the CNN and Transformer architectures, we propose a Dual Di erential Cross Attention Module (DDCAM) to mitigate the adverse e ects stemming from feature discrepancies. Extensive experiments conducted on both real-world and synthetic high-resolution rainy datasets demonstrate the e ectiveness and e ciency of our model.
